{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mumax/pcss/post-processing Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCSS and Linux ( or wsl )\n",
    "\n",
    "### Setting up an ssh key \n",
    "Ressource : [This website](https://www.ssh.com/academy/ssh/key) has a lot of info about SSH in general\n",
    "\n",
    "Using a key is faster and more safe than using a password\n",
    "`ssh-keygen` to create a key, it's better to just leave the default parameters and press Enter a bunch of times\n",
    "\n",
    "`ssh-copy-id username@eagle.man.poznan.pl` (change `username`) used to transfer your public key to pcss ( if everything goes right this should be the last time you use your password to access pcss)\n",
    "\n",
    "`ssh username@eagle.man.poznan.pl` you should be able to connect to pcss without any credential ( the default key path is `~/.ssh/id_rsa` and you don't need to specify it if you didn't change the name)\n",
    "\n",
    "I'm lazy, so I add this line in my .bashrc:\n",
    "`alias sp='ssh -t mathieum@eagle.man.poznan.pl'`\n",
    "\n",
    "I can log into pcss just typing `sp`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting a PCSS folder locally\n",
    "\n",
    "`sshfs username@eagle.man.poznan.pl:/home/users/username/my_pcss_folder /home/local_username/my_local_folder`\n",
    "\n",
    "`sshfs` will mount any folder through ssh. Both folders, local and remote will be kept in sync. You can mount any folder you want, anywhere, but I advise you only mount in your home directory to avoid permission issues. You also can add many arguments to this command, for example :\n",
    "\n",
    "`sshfs -o allow_other -o kernel_cache -o auto_cache -o reconnect -o compression=no -o cache_timeout=600 -o no_readahead -o big_writes -o ServerAliveInterval=15 username@eagle.man.poznan.pl:/home/users/username/my_pcss_folder /home/local_username/my_local_folder`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up mumax on PCSS\n",
    "\n",
    "Mumax is hardly supported anymore, I forked and modified the source code. My version can be found on [github](https://github.com/MathieuMoalic/amumax) \n",
    "\n",
    "Contact me if you find any bugs or want something implemented.\n",
    "\n",
    "Make your life easier, set up simple scripts to automate your workflow\n",
    "#### Examples :\n",
    "```bash\n",
    "export SLURM_TIME_FORMAT=\"%H:%M:%S\"\n",
    "alias rl='source ~/.bashrc'\n",
    "alias sq='sacct -X --format=JobID,JobName%22,State,Elapsed,Submit%10,Start%10,End%10,Nodelist%8,Timelimit -S $(date -d \"3 days ago\" +%D-%R)'\n",
    "alias q='bash ~/scripts/autostart.sh'\n",
    "alias q1='bash ~/scripts/autostart1.sh'\n",
    "```\n",
    "`rl` will reload your .bashrc if you made changes\n",
    "`sq` will show all jobs submitted by you in the last 3 days using the time formating `\"%H:%M:%S\"`\n",
    "`q` and `q1` are the following scripts :\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "for file in *.mx3; do \n",
    "    echo $file\n",
    "    sbatch --job-name=\"${file/.mx3/}\" --output=\"${file/.mx3/}.logs\" $HOME/scripts/mumax_job.sh $file\n",
    "done\n",
    "```\n",
    "and \n",
    "```\n",
    "#!/bin/bash\n",
    "file=$1\n",
    "sbatch --job-name=\"${file/.mx3/}\" --output=\"${file/.mx3/}.logs\" $HOME/scripts/mumax_job.sh $file\n",
    "```\n",
    "They just queue all .mx3 files in the folder ( or just a single 1 with `q1`) using this batch script :\n",
    "\n",
    "```bash\n",
    "#!/bin/bash -l\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --mem=4G\n",
    "#SBATCH --time=15:00:00\n",
    "#SBATCH --partition=tesla\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH --exclude=gpu09\n",
    "\n",
    "module load cuda/10.2.89_440.33.01\n",
    "TMPDIR=\"/mnt/storage_2/scratch/grant_398/mumax_kernels/\"\n",
    "\n",
    "file=$1\n",
    "~/go/bin/mumax3 $file\n",
    "\n",
    "mv \"${file/.mx3/}.logs\" \"${file/.mx3/.out}/slurm.logs\"\n",
    "```\n",
    "\n",
    "`TMPDIR` is necessary to cache the mumax kernels in a global folder so they can be reused, this folder is shared by the whole group so we can use eachother's kernels.\n",
    "\n",
    "`~go/bin/mumax3`: path my compiled mumax\n",
    "\n",
    "`mv \"${file/.mx3/}.logs\" \"${file/.mx3/.out}/slurm.logs\"`: it just moves the batch logs inside my output folder so it's easier to keep everything clean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### virtualenv\n",
    "You need to use a virtualenv, [miniconda](https://repo.anaconda.com/miniconda) is good but feel free to use any of them.\n",
    "\n",
    "To install it in pcss, you can use these commands :\n",
    "\n",
    "```bash\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-py39_4.10.3-Linux-x86_64.sh\n",
    "bash ./Miniconda3-py39_4.10.3-Linux-x86_64.sh\n",
    "```\n",
    "if you take the recommanded default option during the installation, the base virtualenv should be activated everytime you open a shell session.\n",
    "With miniconda, you can use `conda` instead of `pip` i.e:\n",
    "\n",
    "`conda install -c conda-forge jupyterlab`\n",
    "In 99% of the cases, it's the same as using `pip` but sometimes it's better at packaging additional binaries and prevent some obscure platform dependant bugs.\n",
    "\n",
    "#### Jupyter\n",
    "You need Jupyter to post-process your data quickly and efficiently, it's the default tool for data scientists all over the world.\n",
    "Install jupyter `conda install -c conda-forge jupyterlab` \n",
    "\n",
    "You can also use the `Jupyter` extension in VSCode, it's the same thing, just a different UI.\n",
    "\n",
    "For small amounts of data, it's okay to just process it locally, but if it gets large, it will take time to transfer locally.\n",
    "\n",
    "The solution: Run the jupyter server on a pcss node with (almost) infinite resources. But then you need to create an ssh tunnel between the node on pcss and your pc, for example, I would use:\n",
    "\n",
    "`ssh -N -L 8888:e0123:8888 mathieum@eagle.man.poznan.pl`\n",
    "\n",
    "More examples [here](https://www.ssh.com/academy/ssh/tunneling/example)\n",
    "\n",
    "`8888` is the default port for Jupyter\n",
    "`e0123` is the name of a CPU node on PCSS, **it changes every time**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Jupyter\n",
    "it's just an interactive Python Kernel, you can run the cells and any part of your code in any order as you wish.\n",
    "First of all, you can pip install directly in a code cell :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llyr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`llyr` ([source code](https://github.com/MathieuMoalic/llyr)) is the library I wrote to process the data for my own modified version of mumax.\n",
    "The typical output will be name `job1.zarr`\n",
    "\n",
    "The `.zarr` extension means it's using the [zarr](https://zarr.readthedocs.io/en/stable/) format which is extremely useful to process tons of data, very efficiently.\n",
    "\n",
    "`llyr` is built on top of `zarr` which means that pretty much anything in the zarr docs can be done with `llyr`.\n",
    "\n",
    "Examples are the best way to learn, here is a simple code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688334580d6049ddbdf36ade45966804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tree(nodes=(Node(disabled=True, name='/', nodes=(Node(disabled=True, icon='table', name='m (150, 1, 25, 25, 3)â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# All of these libraries are so useful, it's my default import\n",
    "%matplotlib widget\n",
    "from llyr import op # `op` is a shorthand to initialize llyr\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import cmocean\n",
    "from glob import glob\n",
    "\n",
    "m = op(\"job2.out\") \n",
    "m.pp # prints the \"tree\" of the job1 folder, very handy to see the structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you saved snapshots (.png or jpeg images) they won't appear here but they are in the .zarr directory\n",
    "\n",
    "Please check `job1.mx3` to see what kind of data I saved during the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Name</th><td style=\"text-align: left\">/m</td></tr><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">float32</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(150, 1, 25, 25, 3)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(1, 1, 25, 25, 3)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">False</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">Zstd(level=1)</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">1125000 (1.1M)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">815005 (795.9K)</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">1.4</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">150/150</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Name               : /m\n",
       "Type               : zarr.core.Array\n",
       "Data type          : float32\n",
       "Shape              : (150, 1, 25, 25, 3)\n",
       "Chunk shape        : (1, 1, 25, 25, 3)\n",
       "Order              : C\n",
       "Read-only          : False\n",
       "Compressor         : Zstd(level=1)\n",
       "Store type         : zarr.storage.DirectoryStore\n",
       "No. bytes          : 1125000 (1.1M)\n",
       "No. bytes stored   : 815005 (795.9K)\n",
       "Storage ratio      : 1.4\n",
       "Chunks initialized : 150/150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = m['m'][:] # it loads the whole 'magnetization' dataset\n",
    "dataset = m.m[:] # same thing\n",
    "\n",
    "# YOU NEED TO SLICE IT TO GET THE NUMPY ARR\n",
    "dataset = m.m # if you do this witout '[:]' you will only get a pointer to the dataset and not the actual data\n",
    "dataset.info # but you can do that at least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2e5d4185c741be818e48a93ff9b310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9229d0b8b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = m.m[4,0,:,:,2] # slice it like any numpy array\n",
    "plt.figure()\n",
    "plt.imshow(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, but we can do better. So far, these functionality directly come from `zarr` they are general and work on any kind of data.\n",
    "I added some functions to process micromagnetic data more conveniently, let's look at a few of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7b0f30502e4637851b3bab3ae33661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.plot.snapshot(\"m\",z=0,t=-1) # Fancy 2D snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6a492baf214cb291598c2116f67e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f922798fcd0>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.table.t\n",
    "mag = m.table.m[:,2] # tables are merged together by quantity like dataset\n",
    "plt.figure()\n",
    "plt.plot(t,mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command will calculate the fft spectra ( from the table ) for each component \n",
    "#and plot each resonant mode and create an animation for each one\n",
    "m.make_report('m') \n",
    "# find these modes and these spectra saved as a gif in job2.zarr/report/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disp', 'fft_tb', 'fft', 'modes', 'sk_number', 'peaks', 'fminmax', 'anim']\n",
      "['anim', 'fft_tb', 'imshow', 'modes', 'snapshot', 'snapshot_png', 'report', 'sin_anim', 'cross_section']\n"
     ]
    }
   ],
   "source": [
    "# some calculating methods\n",
    "print(list(m.calc.__dict__.keys()))\n",
    "# some plotting methods\n",
    "print(list(m.plot.__dict__.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These methods are very specialized for myself and probably not very useful for you, I encourage you to write your own functions that are build on to of the zarr API and add them to `llyr`"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a0132dff237c21ee6e97555432a1c9a29fff9239a0cb92f96e3c7b72fdb42e7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
